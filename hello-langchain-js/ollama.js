import { Ollama } from "@langchain/ollama";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";

// é…ç½® Ollama æ¨¡å‹
const model = new Ollama({
    baseUrl: "http://localhost:11434", // Ollama é»˜è®¤åœ°å€
    model: "qwen2.5", // ä½¿ç”¨ qwen2.5 æ¨¡å‹
});

// åˆ›å»º Prompt Template
const prompt = ChatPromptTemplate.fromMessages([
    ["human", "ä½ æ˜¯é¡¶çº§çš„çŸ­ç‰‡ä½œå®¶ï¼Œè¯·æ ¹æ®{title}çš„å†…å®¹ï¼Œå†™ä¸€ç¯‡50å­—çš„ç²¾å“çŸ­æ–‡ï¼Œç„¶åç¿»è¯‘æˆè‹±æ–‡ã€‚"],
]);

// åˆ›å»ºè¾“å‡ºè§£æå™¨
const outputParser = new StringOutputParser();

// æ„å»ºå¤„ç†é“¾
const chain = prompt.pipe(model).pipe(outputParser);

// å¼‚æ­¥ä¸»å‡½æ•°
async function main() {
    try {
        console.log("ğŸš€ å¼€å§‹ç”ŸæˆçŸ­æ–‡...\n");
        
        const response = await chain.invoke({
            title: "çª—å¤–",
        });
        
        console.log("âœ… ç”Ÿæˆç»“æœï¼š\n");
        console.log(response);
        console.log("\nâœ¨ å®Œæˆï¼");
        
    } catch (error) {
        console.error("âŒ é”™è¯¯:", error.message);
        
        if (error.message.includes("ECONNREFUSED")) {
            console.error("\nğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ");
            console.error("   è¿è¡Œå‘½ä»¤ï¼šollama serve");
        } else if (error.message.includes("model")) {
            console.error("\nğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿å·²ä¸‹è½½ qwen2.5 æ¨¡å‹");
            console.error("   è¿è¡Œå‘½ä»¤ï¼šollama pull qwen2.5");
        }
        
        process.exit(1);
    }
}

// æ‰§è¡Œä¸»å‡½æ•°
main();