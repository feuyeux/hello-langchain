import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";

// é…ç½®æ™ºè°± AI æ¨¡å‹
const model = new ChatOpenAI({
    modelName: "GLM-4-Plus",
    apiKey: process.env.ZHIPUAI_API_KEY,
    baseUrl: "https://open.bigmodel.cn/api/paas/v4",
    temperature: 0.7,
});

// é…ç½®èŠå¤©æç¤ºæ¨¡æ¿
const prompt = ChatPromptTemplate.fromMessages([
    ["system", "ä½ æ˜¯é¡¶çº§çš„çŸ­ç‰‡ä½œå®¶"],
    ["human", "è¯·æ ¹æ®{title}çš„å†…å®¹ï¼Œå†™ä¸€ç¯‡50å­—çš„ç²¾å“çŸ­æ–‡ï¼Œç„¶åç¿»è¯‘æˆè‹±æ–‡ã€‚"],
]);

// åˆ›å»ºè¾“å‡ºè§£æå™¨
const outputParser = new StringOutputParser();

// æ„å»ºå¤„ç†é“¾
const chain = prompt.pipe(model).pipe(outputParser);

// å¼‚æ­¥ä¸»å‡½æ•°
async function main() {
    try {
        console.log("ğŸš€ å¼€å§‹ç”ŸæˆçŸ­æ–‡...\n");
        
        // ä½¿ç”¨ chain.invoke æ–¹æ³•è°ƒç”¨é“¾
        const response = await chain.invoke({
            title: "çª—å¤–",
        });
        
        console.log("âœ… ç”Ÿæˆç»“æœï¼š\n");
        console.log(response);
        console.log("\nâœ¨ å®Œæˆï¼");
        
    } catch (error) {
        console.error("âŒ é”™è¯¯:", error.message);
        
        if (error.message.includes("API key")) {
            console.error("\nğŸ’¡ æç¤ºï¼šè¯·è®¾ç½®æ™ºè°± AI API Key");
            console.error("   export ZHIPUAI_API_KEY=your_api_key");
            console.error("   æˆ–è¿è¡Œï¼šsource .env.sh");
        } else if (error.response) {
            console.error("å“åº”é”™è¯¯:", error.response.data || error.response);
        }
        
        process.exit(1);
    }
}

// æ‰§è¡Œä¸»å‡½æ•°
main();