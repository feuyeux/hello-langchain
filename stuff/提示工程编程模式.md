# 提示工程编程模式

> <https://newsletter.theaiedge.io/p/prompt-engineering-and-llmops-building>

非技术角度的宣讲，让我们相信提示工程的复杂度就像幼儿园语法课一样（例如“提高你的生产力的前 5 个提示！”），但它实际上比这复杂多了……

![img](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffaeee505-b210-4d65-bca7-82ac3c8d698f_2693x3068.png)

我花了一些时间才逐渐意识到 **提示工程(Prompt Engineering)** 确实值得深入研究！它是至关重要的研究领域，特别是当我们需要使用 LLMs 构建应用程序时。

![img](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc423a23-73ad-43b1-bd88-f250d83fb63e_1280x508.png)

1 通常，人们会直接向 LLM 提问。这就是所谓的**零样本提示(zero-shot prompting)模式**。

2 如果我们在提示中提供几个例子，则称为**少样本提示(few-shot prompting)模式**：

```Shell
"""
Example question
Example answer

Question
What is the answer?
"""
```

![img](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91ca06f7-5653-4161-b14a-6d3b6071f1bd_1395x1592.png)

3 在 少样本提示(few-shot prompting) 中，如果我们能展示出的出具体答案的推理，就可以取得更好的效果。这就是所谓的 "**思维链(Chain of thoughts, CoT)模式**"。

4 与思维链的行为类似，我们也可以在 零样本(zero-shot) 中，通过 "逐步思考(think step by step)" 来提示，这就是所谓的 "**启发(Inception)模式**"。

5 "思维链 "可以采取中间问答的形式（例如，"我需要更多信息来解决问题吗？ -> 是的，我需要"）。这就是所谓的 "**自问自答(Self-ask)模式**"。

6 我们可以通过引用概念或类比（例如，"想象你是一位物理教授，请回答这个问题："）来诱导有针对性的答案。这就是所谓的 "**模因代理(Memetic Proxy)模式**"。

7 我们重复请求相同的查询(queries)，每次得到的答案(answers)是不同的，因此在多次查询中选择一致的答案可以提高答案的质量。这就是所谓的 "**自我****一致性****(Self-consistency)模式**"。

8 如果要与 LLM 交换多条信息，最好使用**记忆模式(memory pattern)**，这样它就可以参考以前的交互。

![img](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe807ac5d-b4dd-41bc-97f3-81fb0b9e0ca9_982x580.png)

9 当 LLM 可以访问工具或数据库时，这就变得很有趣了。模型可以根据问题决定使用什么工具。我们可以提供**问题-行动对(question-action pairs)**的例子（例如，"宇宙的年龄是多少？" -> [在维基百科上搜索]），这就是所谓的 "**行动(Act)模式**"。

10 如果我们从 LLM 中诱导出中间想法（例如，"宇宙的年龄是多少？->"我需要找到更多关于宇宙的信息"->[在维基百科上搜索]），"**原因行动(****[ReAct](https://arxiv.org/abs/2210.03629)****,Reasoning and Acting)模式**"可以得到更好的效果。

![img](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad977d6d-10fb-4b04-a768-860c70274bae_1241x1211.png)

11 我们可以让接下来的提示提取指定的工具的调用信息，并在下一个提示中使用这个结果来回答最初的问题。这就是**链式提示(Prompt chaining)模式**。

12 我们可以通过引入行动计划(plan of action)来解决复杂问题。计划的每一步都可以使用 ReAct 生成自己的行动链(chain of actions)。例如，AutoGPT 在自动驾驶中使用 "**计划和执行(Plan and execute) "模式**来解决复杂问题。

**LLM** 可以被视为某种灵活的子程序，它接受输入并产生输出。**提示**是塑造子程序的模具，用于解决特定问题。

我们可以认为**LLM** 是某种灵活的**子程序(subroutines)**，接受输入并产生输出。 提示是塑造子程序以解决特定问题的**模具(molds)**。 **LLM 应用程序由**这些子程序组成以构建新颖的功能。
